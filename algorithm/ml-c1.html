<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
h1,
h2,
h3,
h4,
h5,
h6,
p,
blockquote {
    margin: 0;
    padding: 0;
}
body {
    font-family: 'Anonymous' "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;
    font-size: 13px;
    line-height: 18px;
    color: #737373;
    background-color: white;
    margin: 10px 13px 10px 13px;
}

@font-face {
    font-family: 'Anonymous';
    src: url(/Users/adavindes/Downloads/font/AnonymousPro-1.002.001/Anonymous\ Pro.ttf);
}

table {
	margin: 10px 0 15px 0;
	border-collapse: collapse;
}
td,th {	
	border: 1px solid #ddd;
	padding: 3px 10px;
}
th {
	padding: 5px 10px;	
}

a {
    color: #0069d6;
}
a:hover {
    color: #0050a3;
    text-decoration: none;
}
a img {
    border: none;
}
p {
    margin-bottom: 9px;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    color: #404040;
    line-height: 36px;
}
h1 {
    margin-bottom: 18px;
    font-size: 30px;
}
h2 {
    font-size: 24px;
}
h3 {
    font-size: 18px;
}
h4 {
    font-size: 16px;
}
h5 {
    font-size: 14px;
}
h6 {
    font-size: 13px;
}
hr {
    margin: 0 0 19px;
    border: 0;
    border-bottom: 1px solid #ccc;
}
blockquote {
    padding: 13px 13px 21px 15px;
    margin-bottom: 18px;
    font-family:georgia,serif;
    font-style: italic;
}
blockquote:before {
    content:"\201C";
    font-size:40px;
    margin-left:-10px;
    font-family:georgia,serif;
    color:#eee;
}
blockquote p {
    font-size: 14px;
    font-weight: 300;
    line-height: 18px;
    margin-bottom: 0;
    font-style: italic;
}
code, pre {
    font-family: Monaco, Andale Mono, Courier New, monospace;
}
code {
    background-color: #fee9cc;
    color: rgba(0, 0, 0, 0.75);
    padding: 1px 3px;
    font-size: 12px;
    -webkit-border-radius: 3px;
    -moz-border-radius: 3px;
    border-radius: 3px;
}
pre {
    display: block;
    padding: 14px;
    margin: 0 0 18px;
    line-height: 16px;
    font-size: 11px;
    border: 1px solid #d9d9d9;
    white-space: pre-wrap;
    word-wrap: break-word;
}
pre code {
    background-color: #fff;
    color:#737373;
    font-size: 11px;
    padding: 0;
}
sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:10px auto;
    }
}
@media print {
	body,code,pre code,h1,h2,h3,h4,h5,h6 {
		color: black;
	}
	table, pre {
		page-break-inside: avoid;
	}
}

</style>
<title>方法概论</title>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['$$$','$$$']]}});</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<h3>方法概论</h3>

<p>统计学习三大要素：模型、策略、算法</p>

<h4>联合概率分布</h4>

<p>对<strong>离散随机变量</strong>而言，联合分布概率质量函数为 Pr(X = x &amp; Y = y)，即</p>

<p>$$$P(X=x\;\mathrm {and} \;Y=y)\;=\;P(Y=y|X=x)P(X=x)=P(X=x|Y=y)P(Y=y)$$$;</p>

<p>因为是概率分布函数，所以必须有</p>

<p>$$$\sum _ {x}\sum _ {y}P(X=x\ \mathrm {and} \ Y=y)=1$$$;</p>

<p>类似地，对<strong>连续随机变量</strong>而言，联合分布概率密度函数为$$$f_{X,Y}(x, y)$$$，其中$$$f _ {Y|X}(y|x)$$$和$$$f _ {X|Y} (x|y)$$$分别代表$$$X = x$$$时$$$Y$$$的条件分布以及$$$Y = y$$$时$$$X$$$的条件分布；$$$fX(x)$$$和$$$fY(y)$$$分别代表$$$X$$$和$$$Y$$$的边缘分布。
同样地，因为是概率分布函数，所以必须有</p>

<p>$$\int _ {x}\int _ {y}f_{X,Y}(x,y)\;dy\;dx=1.$$</p>

<h4>条件概率</h4>

<p>条件概率（英语：conditional probability）就是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为 P（A|B），读作“在B条件下A的概率”。</p>

<h4>期望损失</h4>

<p>$$R _ {exp}(f)=E _ {P}[L(Y,f(X))]=∫_{x×y} L(y,f(x))P(x,y)dxdy$$</p>

<h4>经验损失</h4>

<p>$$R _ {emp}(f)=\frac{1}{N} \sum_{1}^NL(yi,f(xi))$$</p>

<h4>经验风险最小化</h4>

<p>$$min\frac{1}{N}\sum_{i=1}^NL(yi,f(xi))$$</p>

<h4>结构风险最小化</h4>

<p>$$R_{srm}(f)=\frac{1}{N}\sum_i^N=\frac{1}{N}L(yi,f(xi))+λJ(f)$$</p>

<h4>正则化</h4>

<ul>
<li>参数向量 范数</li>
</ul>


<p>为解决过拟合问题，或者说以结构最小化为准则，一般加上 L2 范数</p>

<h4>交叉验证</h4>

<ol>
<li>简单交叉验证</li>
<li><p>S 折交叉验证</p>

<p> 使用最多，首先：随机将已知数据切分为S个互不相交的大小相同的子集</p>

<p> 然后：利用S-1个子集的数据训练模型，利用剩下的一个子集测试模型，将这一过程对可能的S种可能（即划分后，把每个子集都当一次测试集其余训练集）重复进行</p>

<p> 最后选择出S次评测中平均测试误差最小的模型</p></li>
</ol>


<h4>泛化误差上界</h4>

<h5>定理1.1</h5>

<p>对二类分类问题，当假设空间是有限个函数的集合 $$$F = { f_1, f_2,...f_d }$$$ 时，对任意一个函数 $$$f \in F$$$，至少以概率 $$$1 - \delta$$$，以下不等式成立：</p>

<p>$$R(f) \leqslant \hat{R}(f) + \epsilon(d, N, \delta)$$</p>

<p>其中</p>

<p>$$\epsilon(d, N, \delta) = \sqrt{\frac{1}{2N}(logd + log\frac{1}{\delta})}$$</p>

<p><strong>证明</strong></p>

<p>Hoeffdling 不等式：</p>

<p>设 $$$S _ {n}=\sum _ {i=1}^{n} X_{i}$$$ 是独立随机变量 $$$X_1, X_2,...,X_n$$$之和，$$$X_i \in [a_i, b_i]$$$，则对任意 $$$t > 0$$$，以下不等式成立</p>

<p>$$P(S_n - ES_n \geqslant t) \leqslant exp(\frac{-2t^2}{\sum_{i=1}^{n}(b_i - a_i)^2})$$</p>

<p>$$P( ES_n - S_n \geqslant t) \leqslant exp(\frac{-2t^2}{\sum_{i=1}^{n}(b_i - a_i)^2})$$</p>

<p>已知$$$\hat{R}(f)$$$是 $$$N$$$个独立随机变量$$$L(Y, f{X})$$$的样本均值，而 $$$R(f)$$$ 为随机变量$$$L(Y, f{X})$$$的期望，根据上述式二，可做如下推导：</p>

<ol>
<li>对于 $$$\epsilon > 0$$$，可得 $$$N\epsilon > 0$$$</li>
<li>根据$$$\hat{R}(f)$$$ 和 $$$R(f)$$$ 的含义，可得对于独立随机变量$$$L(Y, f{X})$$$，$$$S_{n} = N\hat{R}(f)$$$，而 $$$ES_n = NR(f)$$$</li>
<li>二类分类问题中，随机变量$$$L_i(y_i, f{x_i}) \in [0, 1]$$$</li>
<li><p>从而根据 hoeffdling 不等式2，可得对于 $$$f \in F$$$：</p>

<p> $$P(NR(f) - N\hat{R}(f) \geqslant N\epsilon) \leqslant exp(\frac{-2(N\epsilon)^2}{\sum_{i=1}^{N}(1 - 0)^2})$$</p>

<p> 即</p>

<p> $$P(NR(f) - N\hat{R}(f) \geqslant N\epsilon) \leqslant exp(-2N\epsilon^2)$$</p>

<p> 由于上式左侧 $$$N$$$ 不影响概率，故可约去，即得：</p>

<p> $$P(R(f) - \hat{R}(f) \geqslant \epsilon) \leqslant exp(-2N\epsilon^2)$$</p>

<p> 如此，对于集合$$$F$$$中所有函数$$$f$$$，对上式成立的并集（至少一个函数 $$$f$$$ 成立）的概率 $$$P$$$，存在：</p>

<p> $$P \leqslant dexp(-2N\epsilon^2)$$ 其中 d 为集合中函数个数</p>

<p> 那么对其补集，即对任意 $$$f \in  F$$$，有：</p>

<p> $$P(R(f) - \hat{R}{f} &lt; \epsilon) \geqslant 1-  dexp(-2N\epsilon^2)$$</p>

<p> 令：</p>

<p> $$\delta = dexp(-2N\epsilon^2)$$</p>

<p> 则：</p>

<p> $$P(R(f) - \hat{R}{f} &lt; \epsilon) \geqslant 1 -  \delta$$</p>

<p> 即至少以概率 $$$1 - \delta$$$，$$$R(f) \leqslant \hat{R}(f) + \epsilon(d, N, \delta)$$$，其中由上式 $$$\delta$$$定义倒推可得$$$\epsilon = \sqrt{\frac{1}{2N}(logd + log\frac{1}{\delta}}$$$，定理得证。</p></li>
</ol>


<h4>生成模型与判别模型</h4>

<p><strong>生成模型</strong></p>

<p>生成方法由数据学习联合概率分布$$$P(X,Y)$$$，然后求出条件概率分布 $$$P(Y|X)$$$作为预测的模型。</p>

<p><strong>判别模型</strong></p>

<p>判别方法由数据直接学习决策函数 $$$f(x)$$$ 或者条件概率分布 $$$P(Y|X)$$$作为预测的模型。</p>

<h4>分类问题</h4>

<p>二类分类问题的常用评价指标：</p>

<ul>
<li>精确率</li>
<li>召回率</li>
</ul>


<p>通常以关注的类为正类，其他类为负类，分类器在测试数据集上的预测或正确或不正确，4 种情况出现的总数分别记作：</p>

<p>$$$TP$$$： 将正类预测为正类数
$$$FN$$$： 将正类预测为负类数
$$$FP$$$： 将负类预测为正类数
$$$TN$$$： 将负类预测为负类数</p>

<p>精确率的定义：</p>

<p>$$P = \frac{TP}{TP + FP}$$</p>

<p>召回率的定义：</p>

<p>$$R = \frac{TP}{TP + FN}$$</p>

<p>$$$F_{1}$$$值：</p>

<p>$$\frac{2}{F_{1}} = \frac{1}{P} + \frac{1}{R}$$</p>

<p>即：</p>

<p>$$F_{1} = \frac{2PR}{P + R} = \frac{2TP}{2TP + FP + FN}$$</p>

<h4>标注问题</h4>

<p>学习一个模型，使它能够对观测序列给出标记序列作为预测。标记个数为有限的，但其组合的序列随序列长度呈指数增长。</p>

<p><strong>学习</strong></p>

<p>给定一个训练数据：</p>

<p>$$T = {(x_1, y_1), (x_2, y_2),... ,(x_N, y_N)}$$</p>

<p>学习系统基于训练数据构建一个模型，表示为条件概率为：</p>

<p>$$P(Y^{(1)}, Y^{(2)},..., Y^{(n)} | X^{(1)}, X^{(2)},..., X^{(n)})$$</p>

<p><strong>标注</strong></p>

<p>对新的输入观测序列找到相应的输出标记序列，具体地，对一个观测序列 $$$X _ {N+1} = ({X _ {N+1}^{1}}, {X _ {N+1}^{2}, {X_{N+1}^{3}}})^T$$$</p>

<p>找到使条件概率</p>

<p>$$P(y _ {N+1}^{(1)}, y _ {N+1}^{(2)},..., y _ {N+1}^{(n)} | x _ {N+1}^{(1)}, x _ {N+1}^{(2)},..., x_{N+1}^{(n)})$$</p>

<p>最大的标记序列</p>

<p>$$Y _ {N+1} = (y _ {N+1}^{(1)}, y _ {N+1}^{(2)},..., y _ {N+1}^{(n)})$$</p>

<h4>回归问题</h4>

<p>学习与回归过程类似标注问题，但模型形式为 $$$Y= f(X)$$$，即输入与输出都为连续型变量。</p>

<p>按照输入变量的个数，分为一元回归和多元回归，按照输入变量和输出变量之间关系的类型即模型的类型，分为线性回归和非线性回归。</p>

<p>回归学习最常用的损失函数是平方损失函数，在此情况下，可用最小二乘法求解。</p>
</body>
</html>